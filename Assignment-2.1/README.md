Created a general <b>deep neural network</b> from scratch <b>using numpy</b> that can arbitrary number of hidden layers with arbitrary number of neurons and can work with:<br>
a)Activation functions: ReLU,tanh,sigmoid<br>
b)Loss functions: Mean-Squared Loss(MSE) and cross-entropy loss(CE)<br>
c)Given number of epochs and learning rate<br>
d)Given type of gradient descent which could have learning rate or adaptive learning rate<br>
e)Given batch size <br>
